# WebCrawler
Getting started:
- Edit config
- pip install -r requirement.txt
- python3 main.py

Future plans:
- Use os independant file seperators
- Increase unit testing
- Improve Python module structure

Favourite features:
- Multithreading for faster performance
- Generates xml sitemap showing pages and their assets
- Scrapes all static assets held on the domain
- Prevents duplicating work by holding visited urls and files in a set
- Simple API for instantiating Crawler
- Asynchronous IO
- Configuration to choose: download html, download assets, log an xml sitemap
